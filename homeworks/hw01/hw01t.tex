\documentclass[12pt]{article}

\include{preamble}

\newtoggle{professormode}
% \toggletrue{professormode} %STUDENTS: DELETE or COMMENT this line



\title{MATH 390.4 / 650.2 Spring 2020 Homework \#1}

\author{Tyron Samaroo} %STUDENTS: write your name here

\iftoggle{professormode}{
\date{Due 11:59PM Tuesday, February 11, 2020 under the door of KY604\\ \vspace{0.5cm} \small (this document last updated \currenttime~on \today)}
}

\renewcommand{\abstractname}{Instructions and Philosophy}

\begin{document}
\maketitle

\iftoggle{professormode}{
\begin{abstract}
The path to success in this class is to do many problems. Unlike other courses, exclusively doing reading(s) will not help. Coming to lecture is akin to watching workout videos; thinking about and solving problems on your own is the actual ``working out.''  Feel free to \qu{work out} with others; \textbf{I want you to work on this in groups.}

Reading is still \textit{required}. For this homework set, read the first chapter of \qu{Learning from Data} and the introduction and Chapter 1 of Silver's book. Of course, you should be googling and reading about all the concepts introduced in class online. This is your responsibility to supplement in-class with your own readings.

The problems below are color coded: \ingreen{green} problems are considered \textit{easy} and marked \qu{[easy]}; \inorange{yellow} problems are considered \textit{intermediate} and marked \qu{[harder]}, \inred{red} problems are considered \textit{difficult} and marked \qu{[difficult]} and \inpurple{purple} problems are extra credit. The \textit{easy} problems are intended to be ``giveaways'' if you went to class. Do as much as you can of the others; I expect you to at least attempt the \textit{difficult} problems. 

This homework is worth 100 points but the point distribution will not be determined until after the due date. See syllabus for the policy on late homework.

Up to 7 points are given as a bonus if the homework is typed using \LaTeX. Links to instaling \LaTeX~and program for compiling \LaTeX~is found on the syllabus. You are encouraged to use \url{overleaf.com}. If you are handing in homework this way, read the comments in the code; there are two lines to comment out and you should replace my name with yours and write your section. The easiest way to use overleaf is to copy the raw text from hwxx.tex and preamble.tex into two new overleaf tex files with the same name. If you are asked to make drawings, you can take a picture of your handwritten drawing and insert them as figures or leave space using the \qu{$\backslash$vspace} command and draw them in after printing or attach them stapled.

The document is available with spaces for you to write your answers. If not using \LaTeX, print this document and write in your answers. I do not accept homeworks which are \textit{not} on this printout. Keep this first page printed for your records.

\end{abstract}

\thispagestyle{empty}
\vspace{1cm}
NAME: \line(1,0){380}
\clearpage
}

\problem{These are questions about Silver's book, the introduction and chapter 1.}

\begin{enumerate}

\easysubproblem{What is the difference between \emph{predict} and \emph{forecast}? Are these two terms used interchangably today?}\spc{4}

During Shakespeare's time \emph{predict} and \emph{forecast} had two different meanings. A prediction is something that a fortune teller or a soothsayer would tell you. A forecast is implied planning under certain conditions of uncertainty. Today \emph{predict} and \emph{forecast} are both used interchangeably. 

\easysubproblem{What is John P. Ioannidis's findings and what are its implications?}\spc{5}

John P. Ioannidis publish a paper \qu{Why Most Published Research
Findings Are False.} He concluded in his paper that predictions of medical hypotheses in medical experiments were most likely to fail if applied in the real world. This is trying to imply that having full dependency on predictions can be catastrophic on society especially when they end up being wrong. 


\easysubproblem{What are the human being's most powerful defense (according to Silver)? Answer using the language from class.}\spc{4}

Humans being's most powerful defense according to Silver is our need to detect patterns. We try to predict the pattern of future events of a phenomenon based on our own examinations. 

\easysubproblem{Information is increasing at a rapid pace, but what is not increasing?}\spc{3}

Information is increasing rapidly but the amount of useful information is not. Silver consider the surplus of information as noise and the useful information that's there as the signal which is the truth that we want.
\newpage
\hardsubproblem{Silver admits that we will always be subjectively biased when making predictions. However, he believes there is an objective truth. In class, how did we describe the objective truth? Answer using notation from class i.e. $t,f, g, h^*, \delta, \epsilon, t, z_1, \ldots, z_t, \delta, \mathbb{D}$, $\mathcal{H}, \mathcal{A}, \mathcal{X}, \mathcal{Y}, X, y, n, p$, $x_{\cdot 1}, \ldots, x_{\cdot p}, x_{1 \cdot}, \ldots, x_{n \cdot}$, etc.}\spc{3}

We describe the objective truth as a phenomenon {$y$} is equal to a true function {${t}$} with causal inputs or \qu{\emph{features}} {$z_{1 \cdot}, \ldots, z _{n}$} 
\begin{center}
    {{$y = t(z_{1 \cdot}, \ldots, z _{n}) $}}
\end{center}


\easysubproblem{In a nutshell, what is Karl Popper's (a famous philosopher of science) definition of \emph{science}?}\spc{4}

Karl Popper's definition of science is that a hypothesis was not scientific unless it was falsifiable. This means that if the negation of a hypothesis can also be proven then it would scientific. 

\intermediatesubproblem{Why did the ratings agencies say the probability of a CDO defaulting was 0.12\% instead of the 28\% that actually occurred? Answer using concepts from class.}\spc{4}

The rating agencies were wrong with their prediction because they did not have any historical data so instead they made faulty assumptions that ended up being catastrophic.  

\easysubproblem{What is the difference between \emph{risk} and \emph{uncertainty} according to Silver's definitions?}\spc{4}


\hardsubproblem{How does Silver define \emph{out of sample}? Answer using notation from class i.e. $t,f, g, h^*, \delta, \epsilon, z_1, \ldots, z_t, \delta, \mathbb{D}, \mathcal{H}, \mathcal{A}, \mathcal{X}, \mathcal{Y}, X, y, n, p, x_{\cdot 1}, \ldots, x_{\cdot p}, x_{1 \cdot}, \ldots, x_{n \cdot}$, etc. WARNING: Silver defines \emph{out of sample} completely differently than the literature, than practitioners in industry and how we will define it in class in a month or so. We will explore what he is talking about in class in the future and we will term this concept differently, using the more widely accepted terminology. So please forget the phrase \emph{out of sample} for now as we will introduce it later in class as something else. There will be other such terms in his book and I will provide this disclaimer at these appropriate times.}\spc{7}

\intermediatesubproblem{Look up \emph{bias} and \emph{variance} online or in a statistics textbook. Connect these concepts to Silver's terms \emph{accuracy} and \emph{precision}. This is another example of Silver using non-standard terminology.}\spc{9}

\end{enumerate}


\problem{Below are some questions about the theory of modeling.}

\begin{enumerate}

\easysubproblem{Redraw the illustration from lecture one except do not use the Earth and a table-top globe. The quadrants are connected with arrows. Label these arrows appropriately.}\spc{11}

\begin{tikzpicture}
\tikzstyle{process} = [rectangle, minimum width=3cm, minimum height=1cm, text centered, draw=black]
\tikzstyle{arrow} = [thick,->,>=stealth]
\node (model) [process] {Model};
\node (reality) [process, below of=model, yshift=-3.5cm] {Reality};
\node (data) [process, below of=model, xshift=8.5cm ,yshift=-3.5cm] {Data/Phenomenon};
\node (predict) [process, xshift=8.5cm] {Prediction/Simulation};
\draw [arrow] (reality) -- node[anchor=east] {Aprox} (model);
\draw [arrow] (model) -- node[anchor=east] {} (predict);
\draw [arrow] (reality) -- node[anchor=north] {Measurement} (data);
\draw [arrow] (data) -- node[anchor=north, rotate=-27] {Learning From Data} (model);
\draw [arrow] (predict) -- node[anchor=west] {Validation} (data);
\draw [arrow] (data) -- node[anchor=north] {} (predict);


\end{tikzpicture}
\easysubproblem{Pursuant to the fix in the previous question, how do we define \emph{data} for the purposes of this class?}\spc{2}

In this class we define data as being natural results of measuring a phenomenon. 
\easysubproblem{Pursuant to the fix in the previous question, how do we define \emph{predictions} for the purposes of this class?}\spc{3}

In class we define prediction to be a phenomenon under examination that can modeled.

\easysubproblem{Why are \qu{all models wrong}? We are quoting the famous statisticians George Box and Norman Draper here.}\spc{2}

All models are wrong because given a phenomenon $y$ we are able to understand it only if we know the true function $t$ with casual inputs $(z_{1 \cdot}, \ldots, z _{n})$ but we do not.

\intermediatesubproblem{Why are \qu{[some models] useful}? We are quoting the famous statisticians George Box and Norman Draper here.}\spc{2}

Some models are useful because we can try to approximate the casual inputs $(z_{1 \cdot}, \ldots, z _{n})$
which we can call $(x_{1 \cdot}, \ldots, x _{n})$. In doing so we can try to approximate the phenomenon the best we can. 

\easysubproblem{What is the difference between a "good model" and a "bad model"?}\spc{2}

A \qu{good model} is a model that can make useful predictions given a set of inputs. A \qu{bad model} on the other hand given the same set of inputs result in wrong or not useful predictions. 
\end{enumerate}

\problem{We are now going to investigate the famous English aphorism \qu{an apple a day keeps the doctor away} as a model. We will use this as springboard to ask more questions about the framework of modeling we introduced in this class.}

\begin{enumerate}


\easysubproblem{Is this a mathematical model? Yes / no and why.}\spc{3}

Yes this is a mathematical model because it is saying given an input apple a day you will have an output which is keeping the doctor away.

\easysubproblem{What is(are) the input(s) in this model?}\spc{3}

This model input would just be the apple.

\easysubproblem{What is(are) the output(s) in this model?}\spc{3}

The output would be whether or not the the doctor was kept away. 

\intermediatesubproblem{How good / bad do you think this model is and why?}\spc{3}

This model is bad because based on how it is phrased we are restricted with one input to make a prediction of the given phenomenon.

\easysubproblem{Devise a metric for gauging the main input. Call this $x_1$ going forward.}\spc{4}

A metric for gauging the main input can be represented as $x_1$ which can be whether or not a person ate an apple 

\easysubproblem{Devise a metric for gauging the main output. Call this $y$ going forward.}\spc{4}

A metric for gauging the main output can be represented as $y$ which would be whether or not the person did not have a visit to the doctor

\easysubproblem{What is $\mathcal{Y}$ mathematically?}\spc{3}

$\mathcal{Y}$ mathematically would be the phenomenon that we are trying predict when given a true function $t$ with causal inputs $(z_1, \ldots, z_t)$


\easysubproblem{Briefly describe $z_1, \ldots, z_t$ in English where $y = t(z_1, \ldots, z_t)$ in this \emph{phenomenon} (not \emph{model}).}\spc{3}

The $z_1, \ldots, z_t$ are the true casual inputs that can be passed in the function $t$ to predict the phenomenon.

\easysubproblem{From this point on, you only observe $x_1$. What is $p$ mathematically?}\spc{1}

If we let $p$ denote the number of features or attribute, so that we have a vector $x_i := [x_i_1, \ldots, x_i_p]$ 


\intermediatesubproblem{What is $\mathcal{X}$ mathematically? If your information contained in $x_1$ is non-numeric, you must coerce it to be numeric at this point.}\spc{3}

$\mathcal{X}$ mathematically is the input space such that $x_i := [x_i_1, \ldots, x_i_p] \in \mathcal{X}$

\easysubproblem{How did we term the functional relationship between $y$ and $x_1$? Is it approximate or equals?}\spc{3}

We term $x_1$ to be one of the features which will be a independent variable, but $x_1$ is just an approximation for $y$.

\easysubproblem{Briefly describe \emph{supervised learning}.}\spc{5}

Supervised learning is where we have historical data which can be consider training data that is labeled which we can learn from. 

\easysubproblem{Why is \ewmph{supervised learning} an \emph{empirical solution} and not an \emph{analytic solution}?}\spc{3}

Supervised learning is an \emph{empirical solution} because it is using historical data to make a prediction where analytical solution is given from an integral or derivative. 

\intermediatesubproblem{From this point on, assume we are involved in supervised learning to achieve the goal you stated in the previous question. Briefly describe what $\mathbb{D}$ would look like here.}\spc{3}

$\mathbb{D} = [\mathcal{X}, y]$ $\mathbb{D}$ is our data that has historical examples with label responses. 

\intermediatesubproblem{Briefly describe the role of $\mathcal{H}$ and $\mathcal{A}$ here.}\spc{3}

$\mathcal{H}$ is a set of candidate function h that can approximate f.
$\mathcal{A}$ an algorithm that takes $\mathcal{H}$ and $\mathbb{D}$ and provides g $\in \mathcal{H}$
as the best approximation of f which would be h*

\easysubproblem{If $g = \mathcal{A}(\mathbb{D}, \mathcal{H})$, what should the domain and range of $g$ be?}\spc{3}



\easysubproblem{Is $g \in \mathcal{H}$? Why or why not?}\spc{3}

$g \in \mathcal{H}$ because we defined an algorithm \mathcal{A}

\easysubproblem{Given a never-before-seen value of $x_1$ which we denote $x^*$, what formula would we use to predict the corresponding value of the output? Denote this prediction $\hat{y}^*$.}\spc{1}

\intermediatesubproblem{Is it reasonable to assume $f \in \mathcal{H}$? Why or why not?}\spc{2}

Generally speaking no but there is a $h* \in \matcal{H}$ which is the closes possible model to f

\easysubproblem{In the general modeling setup, if $f \notin \mathcal{H}$, what are the three sources of error? Copy the equation from the class notes. Denote the names of each error and provide a sentence explanation of each. Denote also $e$ and $\mathcal{E}$ using underbraces / overbraces.}\spc{6}

\easysubproblem{In the general modeling setup, for each of the three source of error, explain what you would do to reduce the source of error as best as you can.}\spc{8}

\intermediatesubproblem{In the general modeling setup, make up an $f$, an $h^*$ and a $g$ and plot them on a graph of $y$ vs $x$ (assume $p=1$). Indicate the sources of error on this plot (see last question). Which source of error is missing from the picture? Why?}\spc{11}



\end{enumerate}

\end{document}

%%%%%%%%%%%%%%%%%This following will go in the next homework!!!

\easysubproblem{Regardless of your answer to what $\mathcal{Y}$ was above, we now coerce $\mathcal{Y} = \braces{0,1}$. If we use a threshold model, what would $\mathcal{H}$ be? What would the parameter(s) be?}\spc{3}


\easysubproblem{Give an explicit example of $g$ under the threshold model.}\spc{3}

\problem{These are questions about the linear perceptron. This problem is not related to problem 3.}

\begin{enumerate}

\easysubproblem{For the linear perceptron model and the linear support vector machine model, what is $\mathcal{H}$? Use $b$ as the bias term.}\spc{3}

\intermediatesubproblem{Rewrite the steps of the \emph{perceptron learning algorithm} using $b$ as the bias term.}\spc{13}

\easysubproblem{Illustrate the perceptron as a one-layer neural network with the Heaviside / binary step / indicator function activation function.}\spc{10}

\easysubproblem{Provide an illustration of a two-layer neural network. Be careful to indicate all pieces. If a mathematical object has a different value from another mathematical object, denote it differently.}\spc{10}

\end{enumerate}

\end{document}











%Why was it such a bad idea for the rating agencies to allow their clients to use their formula?
%Explain the different between foxes and hedgehogs

\problem{These are questions about Silver's book, introduction, chapter 1, 2 and 3.}

\begin{enumerate}

\easysubproblem{Explain Hume's problem of induction with the sun rising every day.}\spc{3}

\easysubproblem{Explain the \qu{inverse probability problem.}}\spc{3}

\easysubproblem{What is Bayes' billiard table problem?}\spc{3}

\hardsubproblem{[MA] How did Price use Bayes' idea to prove the existence of the deity?} \spc{3}

\easysubproblem{Why should Bayes Rule really be called \qu{Laplace's Rule?}}\spc{3}

\hardsubproblem{Prove the version of Bayes Rule found on page 20. State your assumption(s) explicitly. Reference class notes as well.}\spc{4}

\easysubproblem{Give two scientific contexts where Laplace used inverse probability theory to solve major problems.}\spc{3}

\hardsubproblem{[MA] Why did Laplace turn into a frequentist later in life?} \spc{3}

\easysubproblem{State Laplace's version of Bayes Rule (p31).} \spc{3}

\easysubproblem{Why was Bayes Rule \qu{damned} (pp36-37)?} \spc{3}

\easysubproblem{According to Edward Molina, what is the prior (p41)?} \spc{3}

\easysubproblem{What is the source of the \qu{credibility} metric that insurance companies used in the 1920's?} \spc{3}

\easysubproblem{Can the principle of inverse probability work without priors? Yes/no.} \spc{1}

\hardsubproblem{In class we discussed the \qu{principle of indifference} which is a term I borrowed from \href{http://www.amazon.com/Philosophical-Theories-Probability-Issues-Science/dp/041518276X/ref=sr_1_1?ie=UTF8&qid=1455112335&sr=8-1&keywords=donald+gillies+theory+of+probability}{Donald Gillies' Philosophical Theories of Probability}. On Wikipedia, it says that Jacob Bernoulli called it the \qu{principle of insufficient reason}. McGrayne in her research of original sources comes up with many names throughout history this principle was named. List all of them you can find here.} \spc{3}

\easysubproblem{Jeffreys seems to be the founding father of modern Bayesian Statistics. But why did the world turn frequentist in the 1920's? (p57)} \spc{3}
\end{enumerate}

\problem{These exercises will review the Bernoulli model.}


\begin{enumerate}

\easysubproblem{If $X \sim \bernoulli{\theta}$, find $\expe{X}$, $\var{X}$, $\support{X}$ and $\Theta$. No need to derive from first principles, just find the formulas.}\spc{2}

\intermediatesubproblem{If $X \sim \bernoulli{\theta}$, find $\median{X}$.}\spc{2}

\intermediatesubproblem{If $X \sim \bernoulli{\theta}$, write the \qu{parametric statistical model} below using the notation we used in class only.}\spc{2}


\intermediatesubproblem{Explain what the semicolon notation in the previous answer indicates. Hint: go back to precalc and think of the function $g(x;a) = ax^2$ }\spc{2}

\easysubproblem{If $\Xoneton \iid \bernoulli{\theta}$, find the likelihood, $\mathcal{L}$, of $\theta$.}\spc{2}

\hardsubproblem{Given the likelihood above, what would $\mathcal{L}$ be if the data was $<0,1,0,1,3.7>$? Why should this answer have to be?}\spc{2}

\easysubproblem{If $\Xoneton \iid \bernoulli{\theta}$, find the log-likelihood of $\theta$, $\ell(\theta)$.}\spc{2}

\hardsubproblem{[MA] If $\Xoneton \iid f(x;\theta)$, explain why the log-likelihood of $\theta$ is normally distributed if $n$ gets large.}\spc{6}

\easysubproblem{If $\Xoneton \iid \bernoulli{\theta}$, find the score function (i.e the derivative of the log-likelihood) of $\theta$.}\spc{2}

\intermediatesubproblem{If $\Xoneton \iid \bernoulli{\theta}$, find the maximum likelihood estimator for $\theta$.}\spc{5}

\easysubproblem{If $\Xoneton \iid \bernoulli{\theta}$, find the maximum likelihood \textit{estimate} for $\theta$.}\spc{1}

\easysubproblem{Given the previous two questions, describe the difference between a random variable and a datum.}\spc{3}

\easysubproblem{If your data is $<0,1,1,0,1,1,0,1,1,1>$, find the maximum likelihood estimate for $\theta$.}\spc{1}

\easysubproblem{Given this data, find a 99\% confidence interval for $\theta$.}\spc{3}

\easysubproblem{Given this data, test $H_0: \theta = 0.5$ versus $H_a: \theta \neq 0.5$.}\spc{7}


\easysubproblem{Write the PDF of $X \sim \normnot{\theta}{1^2}$.}\spc{5}

\hardsubproblem{Find the MLE for $\theta$ if $\Xoneton \iid \normnot{\theta}{1^2}$.}\spc{6}

\hardsubproblem{[MA] Find the MLE for $\theta$ if $\Xoneton \iid \normnot{\mu}{\sigsq}$. Solve the system of equations $\partialop{\mu}{\ell(\theta)} = 0$ and $\partialop{\sigsq}{\ell(\theta)} = 0$ where $\ell(\theta)$ denotes the log likelihood. You can easily find this online. But try to do it yourself.} \spc{20}


\end{enumerate}

\problem{We will review the frequentist perspective here.}

\begin{enumerate}

\hardsubproblem{Why do frequentists have an insistence on $\theta$ being a fixed, immutable quantity? We didn't cover this in class explicitly but it is lurking behind the scenes. Use your reference resources.}\spc{5}

\easysubproblem{What are the three goals of inference? Give short explanations.}\spc{5}

\easysubproblem{What are the three reasons why \emph{frequentists} (adherents to the frequentist perspective) use MLEs i.e. list three properties of MLEs that make them powerful.}\spc{6}

\hardsubproblem{[MA] Give the conditions for asymptotic normality of the MLE,

\beqn
\frac{\thetahatmle - \theta}{\se{\thetahatmle}} \convd \stdnormnot.
\eeqn

You can find them online.}\spc{8}

\hardsubproblem{[MA] $\se{\thetahatmle}$ cannot be found without $\theta$ so we substituted $\thetahatmle$ into $\se{\thetahatmle}$ and called it $\seest{\thetahatmle}$ (note the hat over the SE). Show that this too is asymptotically normal, \ie

\beqn
\frac{\thetahatmle - \theta}{\seest{\thetahatmle}} \convd \stdnormnot
\eeqn

You need the continuous mapping theorem and Slutsky's theorem.
}\spc{4}

\easysubproblem{[MA] Explain why the previous question allows us to build asymptotically valid confidence intervals using $\bracks{\thetahatmle \pm z_{\alpha/2} \seest{\thetahatmle}}$}.\spc{3}

\intermediatesubproblem{Why does all of frequentist inference break down if $n$ isn't large?}\spc{2}

\easysubproblem{Write the most popular two frequentist interpretations of a confidence interval.}\spc{6}

\intermediatesubproblem{Why are each of these unsatisfactory?}\spc{3}

\easysubproblem{What are the two possible outcomes of a hypothesis test?}\spc{1}

\hardsubproblem{[MA] What is the weakness of the interpretation of the $p$-val?}\spc{6}


\end{enumerate}


\problem{We review and build upon conditional probability here.}

\begin{enumerate}


\easysubproblem{Explain why $\cprob{B}{A} \propto \cprob{A}{B}$.}\spc{6}

\easysubproblem{If $B$ represents the hypothesis or the putative cause and $A$ represents evidence or data, explain what Bayesian Conditionalism is, going from which probability statement to which probability statement.}\spc{3}

\end{enumerate}


\end{document}








%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%



\intermediatesubproblem{In class we presented the posterior odds form of Bayes Theorem. Prove it below.}\spc{10}


\intermediatesubproblem{Show that the Bayes Factor is the ratio of posterior odds of the hypothesis to prior odds of the hypothesis.}\spc{2}

\easysubproblem{On the \href{https://en.wikipedia.org/wiki/Bayes_factor}{wikipedia page about Bayes Factors}, Harrold Jeffreys (who we will be returning to later in the semester) gave interpretations of Bayes Factors (which is denoted $K$ there and $B$ in Bolstad's book on page 70). Give the ranges of $K$ here (not in terms of powers of 10, but as a pure number) for his interpretations i.e. \qu{negative,} \qu{strong,} etc.}\spc{3}

\hardsubproblem{[MA] Conceptually why should the likelihood being greater than $\prob{A}$ imply that the hypothesis is more likely after observing the data than before?}\spc{6}
\end{enumerate}

\problem{We examine here paternity testing (i.e. answering the question \qu{is this guy the father of my child?}) via the simplistic test using blood types. These days, more advanced genetic methods exist so these calculations aren't made in practice, but they are a nice exercise. 

First a crash course on basic genetics. In general, everyone has two alleles (your genotype) with one coming from your mother and one coming from your father. The mother passes on each of the alleles with 50\% probability and the father passes on each allele with 50\% probability. One allele gets expressed (your phenotype). So one of the genes shone through (the dominant one) and one was masked (the recessive one). Dominant blood types are A and B and the recessive type is o (lowercase letter). The only way to express phenotype o is to have genotype oo i.e. both genes are o. There is an exception; A and B are codominant meaning that blood type AB tests positive for both A and B.

In this case consider a child of blood type B and the mother of blood type A. Using this \href{http://www.cccoe.net/genetics/blood2.html}{hereditary guide}, we know that the mother's type must be Ao so she passed on an o to the child thus the child got the B from the father. Thus the father had type AB, BB or Bo. I got the following data from \href{http://www.sciencedirect.com/science/article/pii/S1110863011000796}{this paper} (so let's assume this case is in Nigeria in 1998).

\begin{table}
\centering
\begin{tabular}{cc}
Genotype & Frequency \\ \hline
OO	&0.52 \\
AA	&0.0196 \\
AO	&0.2016 \\
BB	&0.0196 \\
BO	&0.2016 \\
AB	&0.0392 \\
\end{tabular}
\end{table}
} 

\begin{enumerate}

\easysubproblem{Bob is the alleged father and he has blood type B but his genotype is unknown. What is the probability he passes on a B to the child?}\spc{3}

\easysubproblem{What is the probability a stranger passes on a B to the child?}\spc{3}

\easysubproblem{Assume our prior is 50-50 Bob is the father, the customary compromise between a possibly bitter mother and father. What is the prior odds of Bob being the father? Don't think too hard about this one; it is marked easy for a reason.}\spc{6}

\hardsubproblem{We are interested in the posterior question. What is the probability Bob is the father given the child with blood type B?}\spc{5}

\hardsubproblem{What is the Bayes Factor here? See (a) and (b).}\spc{5}

\easysubproblem{What is the probability Bob is not the father given the child with blood type B? Should be easy once you have (c) and (e).}\spc{3}

\end{enumerate}


\end{document}